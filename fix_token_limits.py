#!/usr/bin/env python3
"""
Fix Token Limits Script

This script fixes the max_tokens issue for existing Letta agents by updating their
configuration to use safe token limits that don't exceed model capabilities.

Based on the error: max_tokens is too large: 62286. This model supports at most 32768 completion tokens.
"""

import sys
sys.path.append('.')

from letta_client import Letta
from spds import config
import time


def get_client():
    """Get authenticated Letta client."""
    if config.LETTA_ENVIRONMENT == "SELF_HOSTED" and config.LETTA_SERVER_PASSWORD:
        return Letta(token=config.LETTA_SERVER_PASSWORD, base_url=config.LETTA_BASE_URL)
    elif config.LETTA_API_KEY:
        return Letta(token=config.LETTA_API_KEY, base_url=config.LETTA_BASE_URL)
    else:
        return Letta(base_url=config.LETTA_BASE_URL)


def get_safe_token_limit(model_name: str) -> int:
    """Get safe token limit for a model."""
    return config.MODEL_TOKEN_LIMITS.get(
        model_name,
        {"safe_max": config.DEFAULT_MAX_TOKENS}
    )["safe_max"]


def list_all_agents(client):
    """List all agents on the server."""
    try:
        agents = client.agents.list()
        print(f"Found {len(agents)} agents on the server:")
        for i, agent in enumerate(agents, 1):
            model = getattr(agent, 'model', 'Unknown')
            created = str(getattr(agent, 'created_at', 'Unknown'))[:10] if hasattr(agent, 'created_at') else 'Unknown'
            print(f"  {i}. {agent.name} (ID: {agent.id[:8]}...) - Model: {model} - Created: {created}")
        return agents
    except Exception as e:
        print(f"âŒ Error listing agents: {e}")
        return []


def fix_agent_token_limits(client, agent_id: str, agent_name: str, model: str) -> bool:
    """
    Fix token limits for a specific agent.
    
    Note: The Letta API doesn't currently support updating max_tokens on existing agents,
    so this function focuses on verification and recommendations.
    """
    try:
        # Get safe token limit for this model
        safe_limit = get_safe_token_limit(model)
        
        print(f"\nğŸ”§ Processing agent: {agent_name}")
        print(f"   Model: {model}")
        print(f"   Recommended max_tokens: {safe_limit}")
        
        # Try to retrieve current agent configuration
        try:
            agent_details = client.agents.retrieve(agent_id=agent_id)
            print(f"   âœ… Agent accessible and functioning")
            
            # Test if agent can respond (this will reveal token limit issues)
            test_response = client.agents.messages.create(
                agent_id=agent_id,
                messages=[{"role": "user", "content": "Hello, please respond briefly."}]
            )
            
            if test_response and hasattr(test_response, 'messages') and test_response.messages:
                print(f"   âœ… Agent can respond normally - token limits appear OK")
                return True
            else:
                print(f"   âš ï¸  Agent response test failed - may have token limit issues")
                return False
                
        except Exception as e:
            error_str = str(e).lower()
            if "max_tokens" in error_str or "token" in error_str:
                print(f"   âŒ TOKEN LIMIT ERROR: {e}")
                print(f"   ğŸ’¡ This agent needs to be recreated with max_tokens={safe_limit}")
                return False
            else:
                print(f"   âŒ Other error: {e}")
                return False
                
    except Exception as e:
        print(f"   âŒ Failed to process agent {agent_name}: {e}")
        return False


def create_agent_recreation_script(problematic_agents):
    """Create a script to recreate problematic agents with correct token limits."""
    script_content = '''#!/usr/bin/env python3
"""
Agent Recreation Script - Auto-generated by fix_token_limits.py

This script recreates agents that have token limit issues.
Run this script AFTER backing up any important agent data.
"""

import sys
sys.path.append('.')

from letta_client import Letta
from spds import config
from spds.spds_agent import SPDSAgent

def get_client():
    """Get authenticated Letta client."""
    if config.LETTA_ENVIRONMENT == "SELF_HOSTED" and config.LETTA_SERVER_PASSWORD:
        return Letta(token=config.LETTA_SERVER_PASSWORD, base_url=config.LETTA_BASE_URL)
    elif config.LETTA_API_KEY:
        return Letta(token=config.LETTA_API_KEY, base_url=config.LETTA_BASE_URL)
    else:
        return Letta(base_url=config.LETTA_BASE_URL)

def main():
    print("ğŸ”§ Agent Recreation Script")
    print("=" * 50)
    
    client = get_client()
    
    # Agents to recreate (with token limit issues):
'''
    
    for agent_id, agent_name, model in problematic_agents:
        safe_limit = get_safe_token_limit(model)
        script_content += f'''
    print("\\nğŸ”„ Recreating agent: {agent_name}")
    try:
        # Delete old agent with token issues (CAUTION: This removes all conversation history)
        # client.agents.delete(agent_id="{agent_id}")
        print("   âš ï¸  Old agent deletion commented out for safety")
        
        # Create new agent with correct token limits
        # Note: You may need to customize persona/expertise based on the original agent
        new_agent = SPDSAgent.create_new(
            name="{agent_name}_fixed",
            persona="A helpful AI assistant",  # TODO: Customize based on original
            expertise=["general"],  # TODO: Customize based on original  
            client=client,
            model="{model}"
        )
        print(f"   âœ… Created new agent: {{new_agent.name}} with max_tokens={safe_limit}")
        
    except Exception as e:
        print(f"   âŒ Failed to recreate {agent_name}: {{e}}")
'''
    
    script_content += '''
    print("\\nâœ… Agent recreation completed!")
    print("ğŸ’¡ Remember to update any scripts/configs that reference the old agent IDs")

if __name__ == "__main__":
    main()
'''
    
    with open("recreate_agents.py", "w") as f:
        f.write(script_content)
    
    print(f"\nğŸ“ Created recreation script: recreate_agents.py")
    print("   Review and customize it before running!")


def main():
    """Main function to fix token limits across all agents."""
    print("ğŸ”§ Letta Agent Token Limit Fix")
    print("=" * 50)
    print("This script identifies and helps fix agents with token limit issues.")
    print("The error: 'max_tokens is too large: 62286. This model supports at most 32768'")
    print()
    
    # Get client
    try:
        client = get_client()
        print("âœ… Connected to Letta server")
    except Exception as e:
        print(f"âŒ Failed to connect to Letta server: {e}")
        return
    
    # List all agents
    agents = list_all_agents(client)
    if not agents:
        print("No agents found. Exiting.")
        return
    
    print(f"\nğŸ” Testing agents for token limit issues...")
    print("=" * 50)
    
    working_agents = []
    problematic_agents = []
    
    for agent in agents:
        # Small delay to avoid overwhelming the server
        time.sleep(0.5)
        
        model = getattr(agent, 'model', 'openai/gpt-4')  # Default if not found
        success = fix_agent_token_limits(client, agent.id, agent.name, model)
        
        if success:
            working_agents.append((agent.id, agent.name, model))
        else:
            problematic_agents.append((agent.id, agent.name, model))
    
    # Summary
    print(f"\nğŸ“Š SUMMARY")
    print("=" * 50)
    print(f"âœ… Working agents: {len(working_agents)}")
    print(f"âŒ Problematic agents: {len(problematic_agents)}")
    
    if working_agents:
        print(f"\nâœ… These agents are working correctly:")
        for agent_id, name, model in working_agents:
            safe_limit = get_safe_token_limit(model)
            print(f"   - {name} ({model}) - max_tokens: {safe_limit}")
    
    if problematic_agents:
        print(f"\nâŒ These agents have token limit issues:")
        for agent_id, name, model in problematic_agents:
            safe_limit = get_safe_token_limit(model)
            print(f"   - {name} ({model}) - needs max_tokens: {safe_limit}")
        
        print(f"\nğŸ’¡ RECOMMENDATIONS:")
        print("1. For NEW agents: They will automatically use correct token limits")
        print("2. For EXISTING problematic agents: They need to be recreated")
        print("3. Run the web GUI test to see if the issue is resolved")
        
        # Create recreation script
        create_agent_recreation_script(problematic_agents)
    
    print(f"\nğŸ¯ NEXT STEPS:")
    print("1. Test your web GUI - new agents should work correctly")
    print("2. If you still see token errors, check the Letta server logs")
    print("3. Consider recreating problematic agents using the generated script")


if __name__ == "__main__":
    main()